{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = vec1.reshape(-1)\n",
    "    vec2 = vec2.reshape(-1)\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    if similarity<0: similarity = 0\n",
    "    return similarity\n",
    "\n",
    "def similarity_to_probability(similarity):\n",
    "    \"\"\"Convert cosine similarity to a probability-like measure.\"\"\"\n",
    "    # return ((1 + similarity) / 2)  # Rescale to [0,1]\n",
    "    return similarity\n",
    "\n",
    "def joint_probability_two(A, B):\n",
    "    \"\"\"Compute the joint probability of two vectors.\"\"\"\n",
    "    sim_AB = cosine_similarity(A, B)\n",
    "    return similarity_to_probability(sim_AB)\n",
    "\n",
    "def joint_probability_three(A, B, C):\n",
    "    \"\"\"Compute the joint probability of three vectors.\"\"\"\n",
    "    P_AB = joint_probability_two(A, B)\n",
    "    P_BC = joint_probability_two(B, C)\n",
    "    P_CA = joint_probability_two(C, A)\n",
    "    \n",
    "    return P_AB * P_BC * P_CA \n",
    "\n",
    "def joint_vector(A, B):\n",
    "    joint_vector = (A + B) / 2 * cosine_similarity(A, B)\n",
    "    \n",
    "    return joint_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(sentence, model, tokenizer):\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    input_ids = tokens[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.model.embed_tokens(input_ids).squeeze(0)\n",
    "    \n",
    "    embeddings = np.mean(embeddings.cpu().numpy(), axis=0)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"selected_sentences.pickle\", \"rb\") as f:\n",
    "    sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sentence_embeds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"overall_sentence_count.pickle\"):\n",
    "    with open(\"overall_sentence_count.pickle\", \"rb\") as f:\n",
    "        overall_sentence_count = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    all_sentence_counts = []\n",
    "    pbar = tqdm.tqdm(selected_sentence_embeds[:10000])\n",
    "    for target_sentence, target_sentence_embed in pbar:\n",
    "        target_sentence_count = 0\n",
    "        for context_sentence, context_sentence_embed in selected_sentence_embeds:\n",
    "            target_sentence_count+=joint_probability_two(target_sentence_embed, context_sentence_embed)\n",
    "\n",
    "        all_sentence_counts+=[target_sentence_count]\n",
    "\n",
    "    overall_sentence_count = np.mean(all_sentence_counts)*len(selected_sentence_embeds)\n",
    "    with open(\"overall_sentence_count.pickle\", \"wb\") as f:\n",
    "        pickle.dump(overall_sentence_count, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists = [\n",
    "    ([\"兩造\",], [\"雙方\"]),\n",
    "    ([\"上揭\", \"上開\", \"前揭\", \"前開\", \"首揭\"], [\"前述\", \"上述\"]),\n",
    "    ([\"云云\",], [\"等陳述\", \"等語\", \"等等\"]),\n",
    "    ([\"可考\", \"可佐\", \"可按\", \"可稽\", \"可證\", \"足按\", \"足徵\", \"足稽\", \"足憑\", \"足證\"], [\"可以佐證\", \"可供證明\", \"可以證明\", \"足以佐證\", \"足以證明\"]),\n",
    "    ([\"迭\",], [\"接連\", \"多次\"]),\n",
    "    ([\"拘束\",], [\"限制\",]),\n",
    "    ([\"失所附麗\",], [\"失所依附\",]),\n",
    "    ([\"尚非無稽\", \"尚非無憑\", \"尚非無據\", \"尚非虛妄\", \"尚非臆造\"], [\"應可採信\", \"應屬事實\", \"並非全無依據\", \"並不是完全沒有依據\"]),\n",
    "    ([\"所載\",], [\"所記載\",]),\n",
    "    ([\"考諸\", \"徵諸\", \"觀諸\", \"稽之\"], [\"參考\", \"依照\", \"依據\"]),\n",
    "    ([\"質言之\",], [\"簡言之\",]),\n",
    "    ([\"相歧\",], [\"矛盾\",]),\n",
    "    ([\"即非法所不許\", \"依法即無不合\",], [\"符合法律規定\",]),\n",
    "    ([\"礙難採認\",], [\"難以認定\", \"難以採信\", \"不可採\"]),\n",
    "    ([\"矧\",], [\"況且\",]),\n",
    "    ([\"翻異\"], [\"推翻\"]),\n",
    "    ([\"乃\",], [\"於是\",]),\n",
    "    ([\"自白不諱\", \"供認不諱\", \"坦承不諱\"], [\"坦白承認\"]),\n",
    "    ([\"似無可採\", \"似屬無憑\", \"即無可採\", \"即屬無據\", \"尚無可採\", \"尚難憑採\", \"要非可信\", \"要屬虛言\", \"容非可採\"], [\"難以採信\", \"不可採信\", \"尚不足採信\", \"尚不足採證\"]),\n",
    "    ([\"顯有\",], [\"顯然有\", \"顯然屬於\", \"顯然是\"])\n",
    "]\n",
    "\n",
    "for legal_terms, usual_terms in term_lists:\n",
    "\n",
    "    terms = legal_terms+usual_terms\n",
    "    print(\"|\".join(terms))\n",
    "    save_path = os.path.join(\"semantic_surprisals\", \"|\".join(terms))\n",
    "\n",
    "    if os.path.isfile(save_path): continue\n",
    "    term_types = [\"legal\"]*len(legal_terms)+[\"usual\"]*len(usual_terms)\n",
    "\n",
    "\n",
    "    regex_str = \"|\".join(terms)\n",
    "    idx = 0\n",
    "    contexts = {term: [] for term in terms}\n",
    "\n",
    "    non_context_sentences = []\n",
    "    context_sentences = []\n",
    "    term_list = []\n",
    "    for sentence1, sentence2 in zip(sentences[:-1], sentences[1:]):\n",
    "\n",
    "        matches = list(re.finditer(regex_str, sentence2))\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "\n",
    "                context = sentence1+\"，\"+sentence2[:match.start()]\n",
    "                context_sentences.append(context)\n",
    "                term_list.append(match.group())\n",
    "\n",
    "        else:\n",
    "            non_context_sentences+=[sentence1]\n",
    "\n",
    "    non_context_embeds = []\n",
    "    for non_context_sentence in tqdm.tqdm(non_context_sentences):\n",
    "        non_context_embeds+=[get_sentence_embeddings(non_context_sentence, model, tokenizer)]\n",
    "    \n",
    "    context_embeds = []\n",
    "    for context_sentence in tqdm.tqdm(context_sentences):\n",
    "        context_embeds+=[get_sentence_embeddings(context_sentence, model, tokenizer)]\n",
    "\n",
    "    target_context_probs = {term: [] for term in terms}\n",
    "    term_target_context_probs = {term: [] for term in terms}\n",
    "\n",
    "    for term, target_context_embed in tqdm.tqdm([(term, context_embed) for (term, context_embed) in zip(term_list, context_embeds)]):\n",
    "        target_context_counts = []\n",
    "        term_target_context_counts = []\n",
    "\n",
    "        for non_context_embed in non_context_embeds:\n",
    "            target_context_count = joint_probability_two(target_context_embed, non_context_embed)\n",
    "            target_context_counts.append(target_context_count)\n",
    "\n",
    "        for context_embed in context_embeds:\n",
    "            target_context_count = joint_probability_two(target_context_embed, context_embed)\n",
    "            target_context_counts.append(target_context_count)\n",
    "\n",
    "            term_target_context_count = target_context_count\n",
    "            term_target_context_counts.append(term_target_context_count)\n",
    "        \n",
    "            \n",
    "        target_context_prob = np.sum(target_context_counts)/overall_sentence_count\n",
    "        target_context_probs[term].append(target_context_prob)\n",
    "        if np.isnan(target_context_prob) or target_context_prob>1 or target_context_prob<0: raise Exception\n",
    "        \n",
    "\n",
    "        term_target_context_prob = np.sum(term_target_context_counts)/overall_sentence_count\n",
    "        term_target_context_probs[term].append(term_target_context_prob)\n",
    "        if np.isnan(term_target_context_prob) or term_target_context_prob>1 or term_target_context_prob<0: raise Exception\n",
    "\n",
    "    term_surprisals = {term: [] for term in terms}\n",
    "\n",
    "    for term in contexts:\n",
    "        for target_context_prob, term_target_context_prob in zip(target_context_probs[term], term_target_context_probs[term]):\n",
    "            term_surprisal = -np.log(term_target_context_prob/target_context_prob)\n",
    "\n",
    "            term_surprisals[term].append(term_surprisal)\n",
    "\n",
    "    with open(save_path, \"wb\") as f:\n",
    "\n",
    "        pickle.dump((term_surprisals, term_types), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
